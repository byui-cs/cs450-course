<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>CS 450 - Prove</title>
    <link rel="stylesheet" type="text/css" href="../course/style2018.css" />
</head>

<body>
    <div id="courseTitle">
        <span class="icon-byui-logo"></span>
        <h1>Machine Learning &amp; Data Mining | CS 450</h1>
    </div>
    <article>


            <h2>01 Prove : Assignment - Experiment Shell &amp; Hardcoded Classifier</h2>

            <h3>Objective</h3>
            <p>Create an experiment shell that can be used to load data, apply a classification algorithm, and report results.</p>

            <p>As a placeholder, also implement a classifier, "HardCodedClassifier", that always predicts the same class.</p>

            <p>More than anything, the purpose of this assignment is to make sure you have the pieces in place to be successful in future assignments. Next week, we will implement an actual classifier that will make use of the framework you put in place here.</p>
            
            <h3>Instructions</h3>
            <p>In short, write a Python program that can:</p>

            <ol>
                <li><p>Load data</p></li>
                <li><p>Prepare training/test sets</p></li>
                <li><p>Use an existing algorithm to create a model</p></li>
                <li><p>Use that model to make predictions</p></li>
                <li><p>Implement your own new "algorithm"</p></li>
            </ol>

            <p>You are welcome to implement this in Python files using any IDE or as a Jupyter Notebook.</p>

            <p>The following list expounds on each of the steps above. In more detail, your program should:</p>

            <h4>1. Load data</h4>
                <p>Load a dataset containing many instances each with a set of attributes and a target value.</p>

                <p>Initially, use the popular Iris dataset, found in the <a href="http://archive.ics.uci.edu/ml/datasets/Iris" target="_blank">UCI data repository</a> It contains 150 instances of three classes of Irises (50 per class), and four numeric attributes (in addition to the class name).</p>

                <p>Please note that this popular dataset is also natively included in the Python scikit-learn package. You can easily obtain it and view its contents with the following code:</p>

<pre><code class="python">
from sklearn import datasets
iris = datasets.load_iris()

# Show the data (the attributes of each instance)
print(iris.data)

# Show the target values (in numeric format) of each instance
print(iris.target)

# Show the actual target names that correspond to each number
print(iris.target_names)
</code></pre>
                <p>In future weeks, you will need to be able to load data sets from text files as well, including those that have non-numeric data, so you should consider getting into that as an "above and beyond" idea for this week.</p>

            <h4>2. Prepare training/test sets</h4>

                <p>Randomize the data (making sure to keep the targets lined up with their corresponding instances), and split it into a training set (70%) and a testing set (30%).</p>

                <p>You are welcome to do this yourself, slicing arrays, etc., but I would encourage you to look at the <code>train_test_split</code> function in sk-learn which does this for you.</p>

            <h4>3. Use an existing algorithm to create a model</h4>

                <p>Use the Naive Bayes algorithm implementation <code>GaussianNB</code> from <code>sk-learn</code> to train a model based on your training data and its targets. You can train a model with this classifier using its fit function:</p>

<pre><code class="python">
classifier = GaussianNB()
classifier.fit(data_train, targets_train)
</code></pre>

            <h4>4. Use that model to make predictions</h4>

                <p>Use the model created by the <code>fit()</code> function in the last step to predict the targets for your test set data. This can be done with the <code>.predict()</code> function on the classifier (or on the model that is returned by the fit function):</p>

<pre><code class="python">
targets_predicted = classifier.predict(data_test)
</code></pre>

                <p>Then, compare the predicted targets to the actual targets and output the resulting accuracy.</p>

            <h4>5. Implement your own new "algorithm"</h4>
                <p>Once you have the above components working, implement your first "learning algorithm," a HardCodedClassifier that always predicts the same class. In other words, if you are predicting fraudulent versus acceptable credit-card transactions, it would simply always predict "fraudulent." Or, in the case of the Iris dataset, it would always predict the same type of iris (e.g., Setosa, but it doesn't matter which one, just that it always predicts the same one).</p>

                <p>You should create a new class, <code>HardCodedClassifier</code>, that has a <code>.fit()</code> method that accepts a dataset and "learns" (which in this case means it does nothing), and which also has a <code>.predict()</code> method that takes the test data and returns targets. These should be able to be used just like an sk-learn algorithm, like so:</p>

<pre><code class="python">
classifier = HardCodedClassifier()
classifier.fit(data_train, targets_train)
targets_predicted = classifier.predict(data_test)
</code></pre>

                <p>You don't need anything intelligent in your HardCoded classes. The <code>.fit()</code>method can just be empty, or print something to the screen. And the <code>.predict()</code> method can simply loop through the data and return a list of 0's as a prediction, one for each instance. In other words, it always predicts "iris-setosa" or something like that.</p>

                <p>Instantiate your new classifier, "train" it with your training data, then use it to make predictions on the test data.</p>

                <p>Determine the accuracy of your classifier's predictions and report the result as a percentage.</p>

            <h3>Requirements</h3>
            <p>As always, you are encouraged to go above and beyond and take initiative in your learning. As described in the syllabus, meeting the minimum standard requirements can qualify you for 93%, but going above and beyond is necessary to get 100%. The following are the expectations for the minimum standard, with a few suggestions for going above and beyond.</p>

            <h4>Minimum Standard Requirements</h4>
            <ul>
                <li><p>The Iris dataset can be loaded</p></li>
                <li><p>The order of the instances is randomized</p></li>
                <li><p>The dataset can be split into a training / test set</p></li>
                <li><p>The GaussianNB algorithm can be run on the Iris dataset, and be used to make predictions and get results.</p></li>
                <li><p>A HardCodedClassifier class is created with fit and predict methods.</p></li>
                <ul>
                    <li><p>Fit accepts training data and targets</p></li>
                    <li><p>Predict makes a prediction for the data it receives (at this point, it always predicts the same answer)</p></li>
                </ul>
                <li><p>HardCoded classifier can be "trained" and "tested" on the Iris dataset and accuracy on the training set is reported.</p></li>
            </ul>

            <h4>Opportunities to go above and beyond:</h4>
            <ul>
                <li><p>In addition to loading data from the sk-learn package, also, load data from CSV/text files</p></li>
                <li><p>Handling non-numeric data types in CSV/text files</p></li>
                <li><p>Adding user interface components (command line is just fine) to specify various parameters of an experiment (e.g., what dataset to use, what algorithm to use, how to split the training/testing data)</p></li>
                <li><p>Adding <em>n</em>-fold cross validation</p></li>
                <li><p>Any other ideas you have</p></li>
            </ul>            
            
            <h3>Submission</h3>

            <p>When complete, you need to upload <strong>two things</strong> (possibly more than two files) to I-Learn:</p>
            <ol>
                <li><p>Download the <a href="prove01.txt" target="_blank">assignment submission form</a>, answer its questions and upload this form to I-Learn.</p></li>
                <li>
                    <p>Submit your source code to I-Learn. If you would prefer, you can post your source code to a Git repository and provide a link in your submission form.</p>
                    <p>If you used a Jupyter Notebook, do not upload the .ipynb file directly, instead, please export the file to HTML (Click <code>File -> Download as... -> Html</code>). Then, upload the HTML file to I-learn.</p>
                </li>
            </ol>
        </article>

   <script src="../course/js/highlight/highlight.pack.js"></script>
   <script>hljs.initHighlightingOnLoad();</script>

</body>

</html>