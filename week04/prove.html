<!DOCTYPE html>
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <title>CSE 450 - Prove</title>
    <link rel="stylesheet" type="text/css" href="../course/style2018.css" />
</head>

<body>
<div id="courseTitle">
    <span class="icon-byui-logo"></span>
    <h1>Machine Learning &amp; Data Mining | CSE 450</h1>
</div>
    <article>

            <h2>04 Prove : Assignment</h2>
            <p class="subtitle">Decision Tree Classifier</p>

            <h3>Objective</h3>
            <p>Understand the ID3 Decision Tree algorithm and how to apply it.</p>

            <p>Please note that you have 2 weeks for this assignment. This is because it can be a challenge! Do not put this off until next week. You should try to complete the coding portion this week to leave next week for working out the bugs.</p>

            <p>While you're welcome to attempt implementing the ID3 algorithm on your own for a stretch challenge, this is not required. Instead, you can work with an off-the-shelf implementation.</p>

            <h4>Instructions</h4>
            <ol>
                <li>
                    <p>Choose at least 3 different datasets to use the decision tree algorithm on.</p>
                    <p>As you are choosing datasets, make sure that among them you get to handle each of the following (not every dataset must contain all of these items):</p>
                    <ul>
                        <li><p>Numeric data</p></li>
                        <li><p>Categorical data</p></li>
                        <li><p>Missing data</p></li>
                        <li><p>Classification</p></li>
                        <li><p>Regression</p></li>
                    </ul>
                </li>
                <li><p>Make sure you understand what the different options for the algorithm do, how they effect the results, and which would make the most sense for each dataset. You may need to do some experimentation here.</p>
                <li><p>Don't forget to leave time for preprocessing.</p></li>
                <li><p>For categorical data, try different approaches (label encoding, one-hot encoding, etc.) and compare/contrast their effectiveness.</p></li>
                <li><p>For missing data, try different approaches and contrast the results.</p></li>
                <li><p>Try different strategies to reduce the height of the tree (e.g., pruning or limiting the height or the number of samples that go to a leaf) and note their effectiveness.</p></li>
                <li>
                    <p>Prepare a PDF report that includes the results of running the algorithm on the datasets you chose. Also, include discussion of each of the above points (numeric data, missing data, etc.) and the implications of the parameter values, encoding strategies (for categorical data), and performance metrics you chose.</p>
                    <p>Make sure to include in your report the grade category that best matches your assignment and provide a justification for this choice. </p>
                    <p>Finally, submit your code to I-Learn as well as this PDF report.</p>
                </li>
            </ol>
            
            <h3>Datasets</h3>
            <p>For either option, the choice of datasets is up to you. In addition to datasets from previous assignments, you might consider:</p>
            <ul>
                <li><p><a href="https://archive.ics.uci.edu/ml/datasets/Iris" target="_blank" title="Iris Dataset">Iris</a> (our old friend!)</p></li>
                <li><p><a href="https://archive.ics.uci.edu/ml/datasets/Lenses" target="_blank" title="Lenses dataset">Lenses</a></p></li>
                <li><p><a href="https://archive.ics.uci.edu/ml/machine-learning-databases/voting-records/" target="_blank" title="Voting">Voting</a> - Please note that you are trying to predict the political party which is listed as the first column (not last) in the data file.</p></li>
                <li><p><a href="https://archive.ics.uci.edu/ml/datasets/Credit+Approval" target="_blank" title="Credit Screening">Credit Screening</a></p></li>
                <li><p><a href="https://archive.ics.uci.edu/ml/datasets/Chess+%28King-Rook+vs.+King%29" target="_blank" title="Chess Dataset">Chess</a> (King-pawn vs. King)</p></li>
            </ul>



            <h4>Requirements</h4>
            <p>As always, you are encouraged to go above and beyond and take initiative in your learning. As described in the syllabus, meeting the minimum standard requirements can qualify you for 93%, but going above and beyond is necessary to get 100%.</p>
            <p>Ideas for going above and beyond include visualizations, algorithm variations, and implementing your own version of ID3.</p>
            <p>If you create your own implementation of the algorithm, feel free to use the shell you created in week 1 (the HardCodedClassifier) as a starting point.</p>

            <h3>Submission</h3>
            <p>When complete, submit your source file and pdf report (including your self evaluation) to I-Learn.</p>

        </article>
]
</body>

</html>